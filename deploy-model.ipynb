{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Exercise Deploying Model Applications\n",
    "\n",
    "This hands-on guide walks you through the process of building, saving, and deploying a linear regression model as a web application using Flask. In this example, we use a dataset to predict housing prices, and by the end, you'll be able to test your deployed model with new input data.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To complete this guide, you should have the following:\n",
    "- **Python 3.6+** installed on your machine.\n",
    "- Basic understanding of Flask for web development.\n",
    "- Familiarity with libraries such as `scikit-learn`, `Flask`, and `joblib`.\n",
    "- **Postman** or **cURL** for testing the application endpoint.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Step 1: Set Up Your Environment\n",
    "\n",
    "### Create a New Directory  \n",
    "Open your terminal and create a directory for your project:\n",
    "\n",
    "```bash\n",
    "mkdir linear_regression_app\n",
    "cd linear_regression_app\n",
    "```\n",
    "### Set Up a Virtual Environment (Optional but Recommended)\n",
    "\n",
    "```bash\n",
    "python -m venv env\n",
    "source env/bin/activate   # For MacOS/Linux\n",
    ".\\env\\Scripts\\activate    # For Windows\n",
    "```\n",
    "### Install Required Libraries\n",
    "```bash\n",
    "pip install flask scikit-learn joblib pandas\n",
    "```\n",
    "\n",
    "## Step 2: Train and Save  Models\n",
    "\n",
    "Script name: *train_save_model.py*\n",
    "\n",
    "This script is responsible for training various machine learning models (Linear Regression, Logistic Regression, Random Forest, SVM, Decision Tree, KNN, Naive Bayes, Gradient Boosting) and saving them for future use.\n",
    "\n",
    "### Download the Dataset\n",
    "In this example, we’ll use the Boston Housing dataset for linear Regression model. You can load it directly from an online source. Then we will use iris dataset for other models.\n",
    "\n",
    "### Write the Training Script\n",
    "Create a Python file named train_model.py and add the following code to train and save the models in their respective names for easy identification:\n",
    "\n",
    " \n",
    "```python\n",
    "# Imort all required libraries\n",
    "# Import Flask framework for building the web application\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# Import joblib for saving and loading machine learning models\n",
    "import joblib\n",
    "\n",
    "# Import pandas for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Import the Iris dataset for classification tasks\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Import train_test_split for splitting the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import various regression and classification algorithms\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Import mean_squared_error for evaluating the performance of regression models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load Boston Housing dataset for Linear Regression\n",
    "url = 'https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Define features and target variable for Linear Regression\n",
    "X = data.drop('medv', axis=1)\n",
    "y = data['medv']\n",
    "\n",
    "# Split the dataset for Linear Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Linear Regression model\n",
    "linear_regression_model = LinearRegression()\n",
    "linear_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained Linear Regression model\n",
    "joblib.dump(linear_regression_model, 'linear_regression_model.joblib')\n",
    "\n",
    "# Load Iris dataset for Classification\n",
    "iris_data = load_iris()\n",
    "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and save Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=200)\n",
    "logistic_model.fit(X_iris_train, y_iris_train)\n",
    "joblib.dump(logistic_model, 'logistic_regression_model.joblib')\n",
    "\n",
    "# Train and save Random Forest Classifier model\n",
    "random_forest_model = RandomForestClassifier()\n",
    "random_forest_model.fit(X_iris_train, y_iris_train)\n",
    "joblib.dump(random_forest_model, 'random_forest_model.joblib')\n",
    "\n",
    "# Train and save SVM model\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_iris_train, y_iris_train)\n",
    "joblib.dump(svm_model, 'svm_model.joblib')\n",
    "\n",
    "# Train and save Decision Tree Classifier model\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "decision_tree_model.fit(X_iris_train, y_iris_train)\n",
    "joblib.dump(decision_tree_model, 'decision_tree_model.joblib')\n",
    "\n",
    "# Train and save K-Nearest Neighbors model\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_iris_train, y_iris_train)\n",
    "joblib.dump(knn_model, 'knn_model.joblib')\n",
    "\n",
    "# Train and save Naive Bayes model\n",
    "naive_bayes_model = GaussianNB()\n",
    "naive_bayes_model.fit(X_iris_train, y_iris_train)\n",
    "joblib.dump(naive_bayes_model, 'naive_bayes_model.joblib')\n",
    "\n",
    "# Train and save Gradient Boosting Classifier model\n",
    "gradient_boosting_model = GradientBoostingClassifier()\n",
    "gradient_boosting_model.fit(X_iris_train, y_iris_train)\n",
    "joblib.dump(gradient_boosting_model, 'gradient_boosting_model.joblib')\n",
    "\n",
    "```\n",
    "\n",
    "### Run the Training and Saving Script\n",
    "\n",
    "```bash\n",
    "python train_save_model.py\n",
    "```\n",
    "\n",
    "This will train the model and save it as linear_regression_model.joblib in the project directory.\n",
    "\n",
    "\n",
    "## Step 3: Create a Flask Application Script\n",
    "\n",
    "Name: *app.py*\n",
    "\n",
    "### Write the Flask App Code\n",
    "Create a new file named app.py and add the following code to load the saved model and create a prediction endpoint.\n",
    "\n",
    "```python\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "\n",
    "# Load the saved model\n",
    "model = joblib.load('linear_regression_model.joblib')\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define the prediction endpoint\n",
    "@app.route('/predict_housing', methods=['POST'])\n",
    "def predict_housing():\n",
    "    data = request.json  # Get JSON data from request\n",
    "    features = data['features']  # Extract features from the JSON payload\n",
    "\n",
    "    prediction = model.predict([features])  # Make a prediction\n",
    "    return jsonify({'prediction': prediction[0]})  # Return the prediction as JSON\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "```\n",
    "\n",
    "### Run the Flask Application\n",
    "\n",
    "```bash\n",
    "python app.py\n",
    "```\n",
    "\n",
    "You should see output indicating that the server is running, typically on http://127.0.0.1:5002 or port 5001, port 5002 or any port that is set by the user server.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Multiple Model API Endpoints\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Endpoint for Linear Regression (Boston Housing)\n",
    "@app.route('/predict_housing', methods=['POST'])\n",
    "def predict_housing():\n",
    "    data = request.json\n",
    "    features = data['features']\n",
    "    prediction = linear_regression_model.predict([features])\n",
    "    return jsonify({'prediction': prediction[0]})\n",
    "\n",
    "# Endpoint for Logistic Regression (Iris Classification)\n",
    "@app.route('/predict_species_logistic', methods=['POST'])\n",
    "def predict_species_logistic():\n",
    "    data = request.json\n",
    "    features = data['features']\n",
    "    prediction = logistic_model.predict([features])\n",
    "    return jsonify({'prediction': int(prediction[0])})\n",
    "\n",
    "# Endpoint for Random Forest Classifier (Iris Classification)\n",
    "@app.route('/predict_species_random_forest', methods=['POST'])\n",
    "def predict_species_random_forest():\n",
    "    data = request.json\n",
    "    features = data['features']\n",
    "    prediction = random_forest_model.predict([features])\n",
    "    return jsonify({'prediction': int(prediction[0])})\n",
    "\n",
    "# Endpoint for SVM Classifier (Iris Classification)\n",
    "@app.route('/predict_species_svm', methods=['POST'])\n",
    "def predict_species_svm():\n",
    "    data = request.json\n",
    "    features = data['features']\n",
    "    prediction = svm_model.predict([features])\n",
    "    return jsonify({'prediction': int(prediction[0])})\n",
    "\n",
    "# Endpoint for Decision Tree Classifier (Iris Classification)\n",
    "@app.route('/predict_species_decision_tree', methods=['POST'])\n",
    "def predict_species_decision_tree():\n",
    "    data = request.json\n",
    "    features = data['features']\n",
    "    prediction = decision_tree_model.predict([features])\n",
    "    return jsonify({'prediction': int(prediction[0])})\n",
    "\n",
    "# Endpoint for K-Nearest Neighbors Classifier (Iris Classification)\n",
    "@app.route('/predict_species_knn', methods=['POST'])\n",
    "def predict_species_knn():\n",
    "    data = request.json\n",
    "    features = data['features']\n",
    "    prediction = knn_model.predict([features])\n",
    "    return jsonify({'prediction': int(prediction[0])})\n",
    "\n",
    "# Endpoint for Naive Bayes Classifier (Iris Classification)\n",
    "@app.route('/predict_species_naive_bayes', methods=['POST'])\n",
    "def predict_species_naive_bayes():\n",
    "    data = request.json\n",
    "    features = data['features']\n",
    "    prediction = naive_bayes_model.predict([features])\n",
    "    return jsonify({'prediction': int(prediction[0])})\n",
    "\n",
    "# Endpoint for Gradient Boosting Classifier (Iris Classification)\n",
    "@app.route('/predict_species_gradient_boosting', methods=['POST'])\n",
    "def predict_species_gradient_boosting():\n",
    "    data = request.json\n",
    "    features = data['features']\n",
    "    prediction = gradient_boosting_model.predict([features])\n",
    "    return jsonify({'prediction': int(prediction[0])})\n",
    "\n",
    "# Run the app on port 5002\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=5002)\n",
    "\n",
    "\"\"\"---\"\"\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model API Endpoint\n",
    "\n",
    "## Using Postman\n",
    "Here we use **Postman** to validate model endpoints in a development setting. \n",
    "\n",
    "1.\tOpen Postman: \n",
    "2.\tSet Request Type: Select POST as the request method.\n",
    "3.\tEnter Request URL: Use the following URL to target the API endpoint:\n",
    "\n",
    "1.\tOpen **Postman**. Make sure you have the Postman application open and ready to use.\n",
    "2.\tSet the request type: Select **POST** as the request method.\n",
    "3.\tEnter Request URL: Use the following URL to target the API endpoint: http://127.0.0.1:5001/predict_housing\n",
    "\n",
    "4.\t**Configure the Body**:\n",
    "- Go to the Body tab.\n",
    "- Select raw as the data format.\n",
    "- Set the format to JSON (usually available as a dropdown next to “raw”).\n",
    "\n",
    "5.\tEnter the JSON Payload:\n",
    "- Add your feature values in JSON format. This sample uses values from the Boston housing dataset:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"features\": [0.1, 18.0, 2.31, 0.5, 6.578, 65.2, 4.0, 1.0, 300.0, 18.5, 396.9, 4.98, 5.3]\n",
    "}\n",
    "```\n",
    "\n",
    "4.\tUnder the **Body** tab, select raw and set the format to **JSON**.\n",
    "5.\tEnter the JSON payload containing 13 feature values from the demo Boston housing dataset:\n",
    "\n",
    "```bash\n",
    "{\n",
    "    \"features\": [0.1, 18.0, 2.31, 0.5, 6.578, 65.2, 4.0, 1.0, 300.0, 18.5, 396.9, 4.98, 5.3]\n",
    "}\n",
    "```\n",
    "\n",
    "6.\tSend the Request:\n",
    "- Click **Send** to submit your request.\n",
    "\n",
    "7.\tView the Response:\n",
    "- In the **Response** section, you should see a JSON object similar to:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prediction\": -80.40353155317675\n",
    "}\n",
    "```\n",
    "\n",
    "This output confirms that the model API is working as expected and providing predictions based on your input data.\n",
    "\n",
    "\n",
    "## Using cURL\n",
    "\n",
    "Alternatively, you can test the API using cURL from your terminal:\n",
    "\n",
    "```bash\n",
    "curl -X POST http://127.0.0.1:5001/predict_housing \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d \"{\\\"features\\\": [0.1, 18.0, 2.31, 0.5, 6.578, 65.2, 4.0, 1.0, 300.0, 18.5, 396.9, 4.98, 5.3]}\"\n",
    "```\n",
    "\n",
    "Expected Output: Upon running the command, you should receive a JSON response like\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prediction\": -80.40353155317675\n",
    "}\n",
    "```\n",
    "\n",
    "This output verifies that the API correctly processes requests and makes predictions using the model deployed on your Flask server.\n",
    "### Expected JSON Response:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prediction\": 30.08\n",
    "}\n",
    "```\n",
    "This is the predicted median value for the housing data based on the input features.\n",
    "\n",
    "## Important Notes for Deployment\n",
    "\n",
    "This setup is a development deployment only. For production, consider using a robust environment such as Google Cloud, AWS, or Heroku, which allows for scalable, always-on deployments without needing your local server running.\n",
    "\n",
    "With this hands-on guide, you now have a deployed linear regression model API! Test further by modifying the feature values or integrate this setup into more complex applications.\n",
    "## Model Deployment with Streamlit\n",
    "\n",
    "In this exercise, we’ll walk through how to deploy machine learning models using Streamlit, an open-source Python library. Streamlit makes it easy to create web apps for data analysis and machine learning, ideal for showcasing your projects and creating interactive demos.\n",
    "\n",
    "### What You’ll Learn\n",
    "\n",
    "1. **Preparing Models for Deployment**: Train and save models (using supervised learning techniques).\n",
    "2. **Creating an Interactive Web App**: Use Streamlit to build an app that allows users to input data, get predictions, and see results instantly.\n",
    "3. **Deploying the App on Streamlit Cloud**: Publish your app online so anyone can access it via a simple link.\n",
    "\n",
    "### Why Streamlit?\n",
    "\n",
    "Streamlit simplifies the process of turning Python scripts into shareable web applications. It’s especially beneficial for data scientists, ML engineers, and learners who want to quickly deploy models without needing extensive knowledge of front-end development.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "To get the most out of this guide, you should be comfortable with:\n",
    "- Basic Python programming\n",
    "- Machine learning model training and saving\n",
    "- Familiarity with libraries like `joblib`, `sklearn`, and `pandas`\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From API testing to Deployment\n",
    "\n",
    "## Deploying Machine Learning Models with Streamlit\n",
    "\n",
    "In this exercise, we’ll walk through how to deploy machine learning models using Streamlit, an open-source Python library. Streamlit makes it easy to create web apps for data analysis and machine learning, ideal for showcasing your projects and creating interactive demos.\n",
    "\n",
    "### What You’ll Learn\n",
    "\n",
    "1. **Preparing Models for Deployment**: Train and save models (using supervised learning techniques).\n",
    "2. **Creating an Interactive Web App**: Use Streamlit to build an app that allows users to input data, get predictions, and see results instantly.\n",
    "3. **Deploying the App on Streamlit Cloud**: Publish your app online so anyone can access it via a simple link.\n",
    "\n",
    "### Why Streamlit?\n",
    "\n",
    "Streamlit simplifies the process of turning Python scripts into shareable web applications. It’s especially beneficial for data scientists, ML engineers, and learners who want to quickly deploy models without needing extensive knowledge of front-end development.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "To get the most out of this guide, you should be comfortable with:\n",
    "- Basic Python programming\n",
    "- Machine learning model training and saving\n",
    "- Familiarity with libraries like `joblib`, `sklearn`, and `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Your Environment\n",
    "\n",
    "Before you begin, make sure you have the necessary tools installed. Follow these steps to set up your environment:\n",
    "\n",
    "### Install Streamlit\n",
    "You can install Streamlit using pip. Open your terminal and run:\n",
    "\n",
    "```bash\n",
    "pip install streamlit\n",
    "```\n",
    "\n",
    "### Install Required Libraries\n",
    "\n",
    "In addition to Streamlit, you’ll need other libraries for data manipulation and model handling. Install them using:\n",
    "\n",
    "```bash\n",
    "pip install joblib scikit-learn pandas\n",
    "```\n",
    "\n",
    "### Verify Installation\n",
    "\n",
    "To check if Streamlit is installed correctly, run the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "streamlit hello\n",
    "```\n",
    "\n",
    "This command will launch a demo app in your web browser, confirming that everything is set up.\n",
    "\n",
    "## Building Your First Streamlit App\n",
    "\n",
    "Now that your environment is ready, let’s build a simple Streamlit app to deploy a machine learning model.\n",
    "\n",
    "### Create a Python File\n",
    "\n",
    "Create a new Python file (e.g., app.py) where you will write your Streamlit code.\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "At the beginning of your app.py, import the necessary libraries:\n",
    "\n",
    "```python\n",
    "import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "### Load Your Model\n",
    "\n",
    "Assuming you have a trained model saved as a .joblib file, load it in your app:\n",
    "\n",
    "```python\n",
    "model = joblib.load('your_model.joblib')\n",
    "```\n",
    "\n",
    "### Create User Input Fields\n",
    "\n",
    "Use Streamlit’s built-in functions to create input fields for user data. For example:\n",
    "\n",
    "```python\n",
    "st.title(\"Your Model Name\")\n",
    "st.write(\"Enter the data below:\")\n",
    "\n",
    "# Input fields\n",
    "feature1 = st.number_input(\"Feature 1\")\n",
    "feature2 = st.number_input(\"Feature 2\")\n",
    "```\n",
    "\n",
    "### Make Predictions\n",
    "\n",
    "Create a button that, when clicked, will display the model’s predictions based on the user input:\n",
    "\n",
    "```python\n",
    "if st.button(\"Predict\"):\n",
    "    input_data = pd.DataFrame([[feature1, feature2]], columns=[\"Feature 1\", \"Feature 2\"])\n",
    "    prediction = model.predict(input_data)\n",
    "    st.write(f\"Prediction: {prediction[0]}\")\n",
    "```\n",
    "\n",
    "### Run Your App\n",
    "\n",
    "To run your Streamlit app, navigate to your project directory in the terminal and execute:\n",
    "\n",
    "```python\n",
    "streamlit run app.py\n",
    "```\n",
    "\n",
    "This command will launch your app in the default web browser.\n",
    "\n",
    "## Deploying on Streamlit Cloud\n",
    "\n",
    "Once you are satisfied with your app, it’s time to deploy it online.\n",
    "\n",
    "### Create a Streamlit Cloud Account\n",
    "\n",
    "If you don’t have one, sign up for a free account on [Streamlit Cloud](https://streamlit.io/cloud).\n",
    "\n",
    "### Connect Your GitHub Repository\n",
    "\n",
    "1. Create a new GitHub repository for your app code.\n",
    "2. Push your `app.py` and any model files (e.g., `your_model.joblib`) to this repository.\n",
    "\n",
    "### Deploy Your App\n",
    "\n",
    "1. In Streamlit Cloud, click on “New App.”\n",
    "2. Select your GitHub repository and branch.\n",
    "3. Specify the main file (e.g., `app.py`) and click “Deploy.”\n",
    "\n",
    "### Share Your App\n",
    "\n",
    "Once deployed, Streamlit Cloud will provide you with a URL that you can share with others, allowing them to access your app easily.\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this section, you learned how to deploy machine learning models using Streamlit. You set up your environment, built an interactive app, and published it online. Streamlit offers a simple yet powerful way to showcase your models and create engaging user experiences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
